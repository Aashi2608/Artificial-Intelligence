{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "NXCTjPUQQW6G",
        "outputId": "876f3fe3-9f0d-4985-90b8-6d6d185a0784"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f11a1c73-9eda-405e-b5aa-08dbf1439a23\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f11a1c73-9eda-405e-b5aa-08dbf1439a23\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "User uploaded file \"kaggle.json\" with length 64 bytes\n",
            "Mounted at ./gdrive\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "\n",
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('./gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgKDL10vQ1qd",
        "outputId": "69e0b614-5309-4b7a-9ac3-5dfbdb76fec4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/815.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m368.6/815.2 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m890.6/890.6 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.8/225.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.4/291.4 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-ema\n",
            "  Downloading torch_ema-0.3-py3-none-any.whl.metadata (415 bytes)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torch-ema) (2.5.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torch-ema) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torch-ema) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torch-ema) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torch-ema) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torch-ema) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->torch-ema) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->torch-ema) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torch-ema) (3.0.2)\n",
            "Downloading torch_ema-0.3-py3-none-any.whl (5.5 kB)\n",
            "Installing collected packages: torch-ema\n",
            "Successfully installed torch-ema-0.3\n",
            "Cloning into 'CoaT'...\n",
            "remote: Enumerating objects: 1339, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 1339 (delta 10), reused 8 (delta 8), pack-reused 1325 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1339/1339), 7.10 MiB | 32.18 MiB/s, done.\n",
            "Resolving deltas: 100% (464/464), done.\n"
          ]
        }
      ],
      "source": [
        "!pip install -q pytorch-lightning & pip install -q -U albumentations & pip install -q iterative-stratification\n",
        "!pip install -q timm & pip install -q einops & pip install -q pytorch-lightning wandb & pip install torch-ema\n",
        "!git clone https://github.com/mlpc-ucsd/CoaT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60ekoJZ6l5oe",
        "outputId": "a12b67fe-9175-43cc-8246-fd62e0ff9213"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gdcm\n",
            "  Downloading gdcm-1.1-py3-none-manylinux1_x86_64.whl.metadata (167 bytes)\n",
            "Downloading gdcm-1.1-py3-none-manylinux1_x86_64.whl (2.7 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/2.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/2.7 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gdcm\n",
            "Successfully installed gdcm-1.1\n",
            "Collecting pylibjpeg\n",
            "  Downloading pylibjpeg-2.0.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pylibjpeg) (1.26.4)\n",
            "Downloading pylibjpeg-2.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: pylibjpeg\n",
            "Successfully installed pylibjpeg-2.0.1\n",
            "Collecting pylibjpeg-libjpeg\n",
            "  Downloading pylibjpeg_libjpeg-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pylibjpeg-libjpeg) (1.26.4)\n",
            "Downloading pylibjpeg_libjpeg-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pylibjpeg-libjpeg\n",
            "Successfully installed pylibjpeg-libjpeg-2.2.0\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q pydicom==2.4.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjYAxaNH5Mwi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "742da47a-d018-4daf-c4b2-c7e64286bed5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading rsna-2024-lumbar-spine-degenerative-classification.zip to /content\n",
            "100% 28.2G/28.2G [01:48<00:00, 256MB/s]\n",
            "100% 28.2G/28.2G [01:48<00:00, 279MB/s]\n",
            "CPU times: user 4.07 s, sys: 643 ms, total: 4.72 s\n",
            "Wall time: 9min 3s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "!kaggle competitions download -c rsna-2024-lumbar-spine-degenerative-classification\n",
        "!unzip -q rsna-2024-lumbar-spine-degenerative-classification.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4_hWpBqmDLR",
        "outputId": "5f4e556f-8a27-441a-8784-fb38ace04a1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/wadakoki/rsna-newmeta\n",
            "License(s): unknown\n",
            "Downloading rsna-newmeta.zip to /content\n",
            "  0% 0.00/3.76M [00:00<?, ?B/s]\n",
            "100% 3.76M/3.76M [00:00<00:00, 231MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d wadakoki/rsna-newmeta\n",
        "!unzip -q /content/rsna-newmeta.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udl0ms8WpxsC",
        "outputId": "2bc469ab-438d-40cf-9216-2701f24389e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/wadakoki/extended-train-label-coordinates\n",
            "License(s): unknown\n",
            "Downloading extended-train-label-coordinates.zip to /content\n",
            "  0% 0.00/1.31M [00:00<?, ?B/s]\n",
            "100% 1.31M/1.31M [00:00<00:00, 167MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d wadakoki/extended-train-label-coordinates\n",
        "!unzip -q /content/extended-train-label-coordinates.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLLcAGyNRCI9"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "import os\n",
        "import yaml\n",
        "import sys\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "from glob import glob\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW, Adam\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR, StepLR, ReduceLROnPlateau\n",
        "import torch.nn as nn\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, TQDMProgressBar\n",
        "import torchvision.transforms as T\n",
        "import albumentations as A\n",
        "import pandas.api.types\n",
        "import sklearn.metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold, KFold, GroupKFold, StratifiedGroupKFold\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
        "#from torchvision.models.maxvit import MaxVit\n",
        "from timm.models.maxxvit import MaxxVit\n",
        "import timm\n",
        "import scipy\n",
        "import albumentations as A\n",
        "from torchvision.transforms import v2\n",
        "from torchvision import models\n",
        "from einops import repeat\n",
        "from einops.layers.torch import Rearrange\n",
        "from tqdm.auto import tqdm\n",
        "#sys.path.append('/content/CoaT')\n",
        "#from CoaT.src.models.coat import coat_lite_medium\n",
        "from joblib import Parallel, delayed\n",
        "from torch.utils.data import default_collate\n",
        "from torch_ema import ExponentialMovingAverage\n",
        "import pydicom as dcm\n",
        "import transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uD5dNimhiQRQ"
      },
      "source": [
        "## training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-ZN8NGVShsS",
        "outputId": "9d773a50-2629-4420-b162-e863d271a3df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finish seeding with seed 126\n",
            "Training on device cuda\n"
          ]
        }
      ],
      "source": [
        "SEED = 126 # friend's birthday\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True # Fix the network according to random seed\n",
        "    print('Finish seeding with seed {}'.format(seed))\n",
        "\n",
        "seed_everything(SEED)\n",
        "print('Training on device {}'.format(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSaE-eYCSlSx",
        "outputId": "0724154a-bb6a-47d3-b597-021264d6f3c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting config.yaml\n"
          ]
        }
      ],
      "source": [
        "%%writefile config.yaml\n",
        "\n",
        "data_path: \"/content/\"\n",
        "output_dir: \"/content/gdrive/MyDrive/RSNA_SPINE/models/\"\n",
        "\n",
        "seed: 1101\n",
        "\n",
        "train_bs: 2\n",
        "valid_bs: 2\n",
        "workers: 1\n",
        "\n",
        "progress_bar_refresh_rate: 1\n",
        "\n",
        "pseudo_train: 0\n",
        "\n",
        "save_topk: 1\n",
        "fold: 5\n",
        "\n",
        "task:\n",
        "    #kind: 'detect'\n",
        "    kind: 'classify'\n",
        "    #kind: 'depth'\n",
        "    #kind: 'depth2'\n",
        "    #condition: 'nfn'\n",
        "    condition: 'scs'\n",
        "    #condition: 'ss'\n",
        "\n",
        "image_size: 384\n",
        "early_stop:\n",
        "    monitor: \"val_loss\"\n",
        "    mode: \"min\"\n",
        "    patience: 999\n",
        "    verbose: 1\n",
        "\n",
        "trainer:\n",
        "    max_epochs: 7\n",
        "    min_epochs: 7\n",
        "    enable_progress_bar: True\n",
        "    precision: \"16-mixed\"\n",
        "    devices: 1\n",
        "\n",
        "model:\n",
        "    name: \"eff\"\n",
        "    loss_smooth: 0.0\n",
        "    optimizer_params:\n",
        "        #lr: 0.001\n",
        "        lr: 0.00007\n",
        "        weight_decay: 0.0001\n",
        "    scheduler:\n",
        "        #name: \"CosineAnnealingLR\"\n",
        "        name: \"cosine_with_warmup\"\n",
        "        params:\n",
        "            CosineAnnealingLR:\n",
        "                T_max: 20\n",
        "                eta_min: 1.0e-5\n",
        "                last_epoch: -1\n",
        "            cosine_with_warmup:\n",
        "                num_training_steps: 8\n",
        "                num_warmup_steps: 1\n",
        "                num_cycles: 0.5\n",
        "                last_epoch: -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwhSokf9SoHJ"
      },
      "outputs": [],
      "source": [
        "with open(\"config.yaml\", \"r\") as file_obj:\n",
        "    config = yaml.safe_load(file_obj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtT4s_f8iBjX"
      },
      "outputs": [],
      "source": [
        "class ClassDataset(Dataset):\n",
        "    def __init__(self, df, series, coor, meta, condition, usage='train'):\n",
        "        #if condition == 'scs':\n",
        "        #    coor = self.sagt22sagt1(coor, meta)\n",
        "        self.series = series\n",
        "        self.coor = coor\n",
        "        self.meta = meta\n",
        "        self.df = df\n",
        "        self.condition = condition\n",
        "        self.usage = usage\n",
        "        self.sag_window = 5\n",
        "        self.ax_window = 5\n",
        "        if condition == 'scs':\n",
        "            self.label = [\n",
        "                'spinal_canal_stenosis_l1_l2', 'spinal_canal_stenosis_l2_l3', 'spinal_canal_stenosis_l3_l4', 'spinal_canal_stenosis_l4_l5', 'spinal_canal_stenosis_l5_s1'\n",
        "            ]\n",
        "        elif condition == 'ss':\n",
        "            self.label = [\n",
        "                'left_subarticular_stenosis_l1_l2', 'left_subarticular_stenosis_l2_l3', 'left_subarticular_stenosis_l3_l4', 'left_subarticular_stenosis_l4_l5', 'left_subarticular_stenosis_l5_s1',\n",
        "                'right_subarticular_stenosis_l1_l2', 'right_subarticular_stenosis_l2_l3', 'right_subarticular_stenosis_l3_l4', 'right_subarticular_stenosis_l4_l5', 'right_subarticular_stenosis_l5_s1'\n",
        "            ]\n",
        "        elif condition == 'nfn':\n",
        "            self.label = [\n",
        "                'left_neural_foraminal_narrowing_l1_l2', f'left_neural_foraminal_narrowing_l2_l3', f'left_neural_foraminal_narrowing_l3_l4', f'left_neural_foraminal_narrowing_l4_l5', f'left_neural_foraminal_narrowing_l5_s1',\n",
        "                'right_neural_foraminal_narrowing_l1_l2', f'right_neural_foraminal_narrowing_l2_l3', f'right_neural_foraminal_narrowing_l3_l4', f'right_neural_foraminal_narrowing_l4_l5', f'right_neural_foraminal_narrowing_l5_s1'\n",
        "            ]\n",
        "        self.id = df.loc[~(df[self.label].isna().any(axis=1)), 'study_id'].unique()\n",
        "        self.id = list(set(self.id) - set([3637444890]))\n",
        "        #self.id = [2773343225]\n",
        "        #self.id = [1782095928]\n",
        "        for l in self.label:\n",
        "            df[l] = df[l].map({'Normal/Mild': 0, 'Moderate': 1, 'Severe': 2})\n",
        "\n",
        "        self.wide_resize = v2.Resize((128, 224))\n",
        "        #self.wide_resize = v2.Resize((224, 224))\n",
        "        self.rec_resize = v2.Resize((256, 256))\n",
        "        self.resize = v2.Resize((128, 128))\n",
        "        self.resize_3d = v2.Resize((256, 256))\n",
        "        self.pre_resize = v2.Resize((512, 512))\n",
        "        self.wide_transforms = A.Compose([\n",
        "            A.RandomBrightnessContrast(p=0.25),\n",
        "            A.ShiftScaleRotate(shift_limit=0.1, scale_limit=(-0.1, 0.1), rotate_limit=20, border_mode=0, p=0.5),\n",
        "            A.Resize(128, 224),\n",
        "        ])\n",
        "        self.rec_transforms = A.Compose([\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.RandomBrightnessContrast(p=0.25),\n",
        "            A.ShiftScaleRotate(shift_limit=0.1, scale_limit=(-0.1, 0.1), rotate_limit=20, border_mode=0, p=0.5),\n",
        "            A.Resize(256, 256),\n",
        "        ])\n",
        "    def __getitem__(self, index):\n",
        "        study_id = self.id[index]\n",
        "        res = {}\n",
        "        if self.condition == 'scs':\n",
        "            sagt2_img, ax_img, sagt1_img, sagt2_depth, ax_depth, sagt1_depth = self.for_scs(study_id)\n",
        "            res['sagt2'] = sagt2_img.to(torch.float32)\n",
        "            res['ax'] = ax_img.to(torch.float32)\n",
        "            res['sagt1'] = sagt1_img.to(torch.float32)\n",
        "            #res['sagt1'] = sagt1_img.to(torch.float32)\n",
        "            res['sagt2_depth'] = sagt2_depth\n",
        "            res['ax_depth'] = ax_depth\n",
        "            res['sagt1_depth'] = sagt1_depth\n",
        "            #res['sagt1'] = sagt1_img.to(torch.float32)\n",
        "\n",
        "        label = self.df.loc[(self.df.study_id==study_id), self.label].values\n",
        "        label = torch.tensor(label).squeeze().to(torch.long)\n",
        "        res['label'] = label\n",
        "        return res\n",
        "\n",
        "    def crop(self, image, x, y, z, x_left, x_right, y_bottom, y_top, wide):\n",
        "        size = [image[i].shape for i in z]\n",
        "        data = torch.stack([torch.tensor(self.pre_resize(torch.tensor(image[i])[None, ...]).squeeze()[max(int((y/shape[0])*512-y_top), 0):int((y/shape[0])*512+y_bottom), max(int((x/shape[1])*512-x_left), 0): int((x/shape[1])*512+x_right)]) for i, shape in zip(z, size)])\n",
        "        if wide:\n",
        "            data = self.wide_resize(data)\n",
        "        else:\n",
        "            data = self.rec_resize(data)\n",
        "        if self.usage == 'train':\n",
        "\n",
        "            if wide:\n",
        "                data = torch.tensor(self.wide_transforms(image=data.numpy().transpose((1, 2, 0)).astype(np.float32))['image'].transpose((2, 0, 1)))\n",
        "            else:\n",
        "                data = torch.tensor(self.rec_transforms(image=data.numpy().transpose((1, 2, 0)).astype(np.float32))['image'].transpose(2, 0, 1))\n",
        "        return data\n",
        "\n",
        "    def for_scs(self, study_id):\n",
        "        sagt2_meta = self.meta.loc[(self.meta.study_id==study_id) & (self.meta.series_description=='Sagittal T2/STIR')]\n",
        "        #display(sagt2_meta)\n",
        "        ax_meta = self.meta.loc[(self.meta.study_id==study_id) & (self.meta.series_description=='Axial T2')]\n",
        "        sagt1_meta = self.meta.loc[(self.meta.study_id==study_id) & (self.meta.series_description=='Sagittal T1')]\n",
        "        #display(ax_meta)\n",
        "        sagt2_meta = sagt2_meta.sort_values('ipp_x', ascending=True).reset_index(drop=True)\n",
        "        ax_meta = ax_meta.sort_values('ipp_z', ascending=False).reset_index(drop=True)\n",
        "        sagt1_meta = sagt1_meta.sort_values('ipp_x', ascending=True).reset_index(drop=True)\n",
        "        sagt2_img = [self.normalize(self.load_dicom(f'/content/train_images/{row.study_id}/{row.series_id}/{row.instance_number}.dcm')) for _, row in sagt2_meta.iterrows()]\n",
        "        ax_img = [self.normalize(self.load_dicom(f'/content/train_images/{row.study_id}/{row.series_id}/{row.instance_number}.dcm')) for _, row in ax_meta.iterrows()]\n",
        "        sagt1_img = [self.normalize(self.load_dicom(f'/content/train_images/{row.study_id}/{row.series_id}/{row.instance_number}.dcm')) for _, row in sagt1_meta.iterrows()]\n",
        "        sagt1_img = [img if (img.shape[0]> 1 and img.shape[1] > 1) else np.zeros((512, 512)) for img in sagt1_img]\n",
        "        sagt2_sub_coor = self.coor.loc[(self.coor.study_id==study_id) & (self.coor.condition=='Spinal Canal Stenosis')]\n",
        "        ax_right_sub_coor = self.coor.loc[(self.coor.study_id==study_id) & (self.coor.condition=='Right Subarticular Stenosis')]\n",
        "        ax_left_sub_coor = self.coor.loc[(self.coor.study_id==study_id) & (self.coor.condition=='Left Subarticular Stenosis')]\n",
        "        sagt1_sub_coor = self.coor.loc[(self.coor.study_id==study_id) & (self.coor.condition=='LR Neural Foraminal Narrowing')]\n",
        "\n",
        "        # SAGITTAL T2\n",
        "        sagt2_dict = {}\n",
        "        sagt2_label_dict = {}\n",
        "        for _, row in sagt2_sub_coor.iterrows():\n",
        "            label = 2\n",
        "            u = np.random.uniform(0, 1)\n",
        "            if u < 0.7:\n",
        "                z_shift = 0\n",
        "            elif u > 0.7 and u < 0.95:\n",
        "                z_shift = np.random.choice([-1, 1])\n",
        "            else:\n",
        "                z_shift = np.random.choice([-2, 2])\n",
        "            if self.usage == 'train':\n",
        "                y_shift = random.randint(-10, 10)\n",
        "                x_shift = random.randint(-10, 10)\n",
        "                #z_shift = random.randint(-1, 1)\n",
        "            else:\n",
        "                y_shift = 0\n",
        "                x_shift = 0\n",
        "                #z_shift = 0#random.randint(-2, 2)\n",
        "            #display(sagt2_meta)\n",
        "            #display(row)\n",
        "            sagt2_label_dict[row.level] = label + z_shift\n",
        "            #if label + z_shift < 0:\n",
        "            #    sagt2_label_dict[row.level] = 0\n",
        "            #elif label + z_shift > 2:\n",
        "            #    sagt2_label_dict[row.level] = 2\n",
        "            mid = sagt2_meta.loc[(sagt2_meta.series_id==row.series_id)&(sagt2_meta.instance_number==row.instance_number)].index[0]\n",
        "            if row.level == 'L5/S1':\n",
        "                ushift = 20\n",
        "            else:\n",
        "                ushift = 0\n",
        "            z = [min(max(mid+w+z_shift, 0), len(sagt2_meta)-1) for w in range(-(self.sag_window-1)//2, ((self.sag_window-1)//2)+1)]\n",
        "            sagt2_dict[row.level] = self.crop(sagt2_img, row.x+x_shift, row.y+y_shift, z, 96, 32, 40+ushift, 40-ushift, wide=True)\n",
        "        sagt2_label = {l: torch.tensor(sagt2_label_dict.get(l, 2)).to(torch.long) for l in ['L1/L2', 'L2/L3', 'L3/L4', 'L4/L5', 'L5/S1']}\n",
        "        # AXIAL T2\n",
        "        #in_list = ax_meta.instance_number.tolist()\n",
        "        ax_dict = {}\n",
        "        ax_label_dict = {}\n",
        "        if np.random.choice([0, 1]) == 0:\n",
        "            ax_sub_coor = ax_right_sub_coor\n",
        "            lrshift = +20\n",
        "        else:\n",
        "            ax_sub_coor = ax_left_sub_coor\n",
        "            lrshift = -20\n",
        "        for _, row in ax_sub_coor.iterrows():\n",
        "            label = 2\n",
        "            u = np.random.uniform(0, 1)\n",
        "            if u < 0.5:\n",
        "                z_shift = 0\n",
        "            elif u > 0.5 and u < 0.85:\n",
        "                z_shift = np.random.choice([-1, 1])\n",
        "            else:\n",
        "                z_shift = np.random.choice([-2, 2])\n",
        "            if self.usage == 'train':\n",
        "                y_shift = random.randint(-10, 10)\n",
        "                x_shift = random.randint(-10, 10)\n",
        "                #z_shift = random.randint(-1, 1)\n",
        "            else:\n",
        "                y_shift = 0\n",
        "                x_shift = 0\n",
        "                #z_shift = 0#random.randint(-1, 1)\n",
        "            ax_label_dict[row.level] = label + z_shift\n",
        "            ax_meta_sub = ax_meta.loc[(ax_meta.series_id==row.series_id)]\n",
        "            ax_meta_sub_original_idx = ax_meta_sub.index.tolist()\n",
        "            ax_meta_sub = ax_meta_sub.reset_index(drop=True)\n",
        "            #display(ax_meta)\n",
        "            #display(ax_meta_sub)\n",
        "            #display(row)\n",
        "            mid = ax_meta_sub.loc[(ax_meta_sub.instance_number==row.instance_number)].index[0]\n",
        "            z = [min(max(mid+w+z_shift, 0), len(ax_meta_sub)-1) for w in range(-(self.ax_window-1)//2, ((self.ax_window-1)//2)+1)]\n",
        "            ax_dict[row.level] = self.crop([ax_img[i] for i in range(len(ax_img)) if i in ax_meta_sub_original_idx], row.x+x_shift+lrshift, row.y+y_shift, z, 96, 96, 96, 96, wide=False)\n",
        "        ax_label = {l: torch.tensor(ax_label_dict.get(l, 2)).to(torch.long) for l in ['L1/L2', 'L2/L3', 'L3/L4', 'L4/L5', 'L5/S1']}\n",
        "\n",
        "        # SAGT1\n",
        "        sagt1_dict = {}\n",
        "        sagt1_label_dict = {}\n",
        "        for _, row in sagt1_sub_coor.iterrows():\n",
        "            label = 2\n",
        "            u = np.random.uniform(0, 1)\n",
        "            if u < 0.7:\n",
        "                z_shift = 0\n",
        "            elif u > 0.7 and u < 0.95:\n",
        "                z_shift = np.random.choice([-1, 1])\n",
        "            else:\n",
        "                z_shift = np.random.choice([-2, 2])\n",
        "            if self.usage == 'train':\n",
        "                y_shift = random.randint(-10, 10)\n",
        "                x_shift = random.randint(-10, 10)\n",
        "                #z_shift = random.randint(-1, 1)\n",
        "            else:\n",
        "                y_shift = 0\n",
        "                x_shift = 0\n",
        "                #z_shift = 0#random.randint(-1, 1)\n",
        "            if row.level == 'L5/S1':\n",
        "                ushift = 20\n",
        "            else:\n",
        "                ushift = 0\n",
        "            sagt1_label_dict[row.level] = label + z_shift\n",
        "            sagt1_meta_sub = sagt1_meta.loc[(sagt1_meta.series_id==row.series_id)]\n",
        "            sagt1_meta_sub_original_idx = sagt1_meta_sub.index.tolist()\n",
        "            sagt1_meta_sub = sagt1_meta_sub.reset_index(drop=True)\n",
        "            #display(sagt1_meta)\n",
        "            #display(sagt1_meta_sub)\n",
        "            #display(row)\n",
        "            mid = sagt1_meta_sub.loc[(sagt1_meta_sub.instance_number==row.instance_number)].index[0]\n",
        "            z = [min(max(mid+w+z_shift, 0), len(sagt1_meta_sub)-1) for w in range(-(self.sag_window-1)//2, ((self.sag_window-1)//2)+1)]\n",
        "            #print(z)\n",
        "            sagt1_dict[row.level] = self.crop([sagt1_img[i] for i in range(len(sagt1_img)) if i in sagt1_meta_sub_original_idx], row.x+x_shift, row.y+y_shift, z, 96, 64, 32+ushift, 32-ushift, wide=True)\n",
        "        sagt1_label = {l: torch.tensor(sagt1_label_dict.get(l, 2)).to(torch.long) for l in ['L1/L2', 'L2/L3', 'L3/L4', 'L4/L5', 'L5/S1']}\n",
        "\n",
        "        sagt2_img = [sagt2_dict.get(l, torch.zeros((self.sag_window, 128, 224))) for l in ['L1/L2', 'L2/L3', 'L3/L4', 'L4/L5', 'L5/S1']]\n",
        "        ax_img = [ax_dict.get(l, torch.zeros((self.ax_window, 256, 256))) for l in ['L1/L2', 'L2/L3', 'L3/L4', 'L4/L5', 'L5/S1']]\n",
        "        sagt1_img = [sagt1_dict.get(l, torch.zeros((self.sag_window, 128, 224))) for l in ['L1/L2', 'L2/L3', 'L3/L4', 'L4/L5', 'L5/S1']]\n",
        "        return torch.stack(sagt2_img).contiguous(), torch.stack(ax_img).contiguous(), torch.stack(sagt1_img).contiguous(), sagt2_label, ax_label, sagt1_label\n",
        "\n",
        "    def normalize(self, x):\n",
        "        lower, upper = np.percentile(x, (1, 99))\n",
        "        x = np.clip(x, lower, upper)\n",
        "        x = x - np.min(x)\n",
        "        x = x / np.max(x)\n",
        "        return x\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.id)\n",
        "\n",
        "    def load_dicom(self, path):\n",
        "        dicom = dcm.dcmread(path)\n",
        "        data = dicom.pixel_array\n",
        "        return data\n",
        "\n",
        "    def check_position(self, first, last, pos):\n",
        "        first_dcm = dcm.read_file(first)\n",
        "        last_dcm = dcm.read_file(last)\n",
        "        first_dcm = first_dcm.ImagePositionPatient[pos]\n",
        "        last_dcm = last_dcm.ImagePositionPatient[pos]\n",
        "        if pos == 0:\n",
        "            return first_dcm > last_dcm\n",
        "        elif pos == 2:\n",
        "            return first_dcm < last_dcm\n",
        "        else:\n",
        "            raise ValueError\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsnYkUSQk6p6"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class SCSDepthDetectLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SCSDepthDetectLoss, self).__init__()\n",
        "\n",
        "    def forward(self, outputs, targets):\n",
        "        loss = 0\n",
        "        for level in ['L1/L2', 'L2/L3', 'L3/L4', 'L4/L5', 'L5/S1']:\n",
        "            #print(outputs[level].shape, targets[level].shape)\n",
        "            _loss = nn.functional.cross_entropy(outputs[level], targets[level].reshape(-1))\n",
        "            loss += _loss\n",
        "        return loss/5\n",
        "\n",
        "class NFNSSDepthDetectLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NFNSSDepthDetectLoss, self).__init__()\n",
        "\n",
        "    def forward(self, outputs, targets):\n",
        "        loss = 0\n",
        "        for level in ['left_L1/L2', 'left_L2/L3', 'left_L3/L4', 'left_L4/L5', 'left_L5/S1',\n",
        "                  'right_L1/L2', 'right_L2/L3', 'right_L3/L4', 'right_L4/L5', 'right_L5/S1']:\n",
        "            _loss = nn.functional.cross_entropy(outputs[level], targets[level].reshape(-1))\n",
        "            loss += _loss\n",
        "        return loss/10\n",
        "class SCSNFNSSLoss(nn.Module):\n",
        "    def __init__(self, is_train=False):\n",
        "        super(SCSNFNSSLoss, self).__init__()\n",
        "        self.loss = nn.CrossEntropyLoss(weight=torch.tensor([1.0, 2.0, 4.0]).to(device))\n",
        "        self.aux_loss_ax = nn.CrossEntropyLoss(weight=torch.tensor([1.0, 2.0, 4.0]).to(device))\n",
        "        self.aux_loss_sagt2 = nn.CrossEntropyLoss(weight=torch.tensor([1.0, 2.0, 4.0]).to(device))\n",
        "        self.aux_loss_sagt1 = nn.CrossEntropyLoss(weight=torch.tensor([1.0, 2.0, 4.0]).to(device))\n",
        "        self.is_train = is_train\n",
        "    def forward(self, outputs, targets, ax=None, sagt2=None, sagt1=None):\n",
        "        targets = targets.reshape(-1)\n",
        "        #print(outputs, targets, outputs.shape, targets.shape)\n",
        "        ax_loss = 0\n",
        "        sagt2_loss = 0\n",
        "        sagt1_loss = 0\n",
        "        num_loss = 1\n",
        "        loss = self.loss(outputs, targets)\n",
        "        if ax is not None:\n",
        "            ax_loss = self.aux_loss_ax(ax, targets)\n",
        "            if self.is_train:\n",
        "                loss += ax_loss*0.5\n",
        "                num_loss += 0.5\n",
        "        if sagt2 is not None:\n",
        "            sagt2_loss = self.aux_loss_sagt2(sagt2, targets)\n",
        "            if self.is_train:\n",
        "                loss += sagt2_loss*0.5\n",
        "                num_loss += 0.5\n",
        "        if sagt1 is not None:\n",
        "            sagt1_loss = self.aux_loss_sagt1(sagt1, targets)\n",
        "            if self.is_train:\n",
        "                loss += sagt1_loss*0.5\n",
        "                num_loss += 0.5\n",
        "        #print(loss)\n",
        "        loss = loss/num_loss\n",
        "        return loss, ax_loss, sagt2_loss, sagt1_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VErXnEIDmGoG"
      },
      "outputs": [],
      "source": [
        "class LSTMMIL(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_classes):\n",
        "        super(LSTMMIL, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, input_dim//2, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n",
        "        self.aux_attention = nn.Sequential(\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(input_dim, 1)\n",
        "        )\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(input_dim, 1)\n",
        "        )\n",
        "    def forward(self, bags):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            bags: (batch_size, num_instances, input_dim)\n",
        "\n",
        "        Returns:\n",
        "            logits: (batch_size, num_classes)\n",
        "        \"\"\"\n",
        "        batch_size, num_instances, input_dim = bags.size()\n",
        "        bags_lstm, _ = self.lstm(bags)\n",
        "        attn_scores = self.attention(bags_lstm).squeeze(-1)\n",
        "        aux_attn_scores = self.aux_attention(bags_lstm).squeeze(-1)\n",
        "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
        "        weighted_instances = torch.bmm(attn_weights.unsqueeze(1), bags_lstm).squeeze(1)  # (batch_size, input_dim)\n",
        "        return weighted_instances, aux_attn_scores\n",
        "\n",
        "\n",
        "class SCSMIL(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.sagt2_encoder = timm.create_model('convnext_small.fb_in22k_ft_in1k_384', in_chans=1, pretrained=True, num_classes=0)\n",
        "        #self.sagt1_encoder = timm.create_model('convnext_base.fb_in22k_ft_in1k_384', in_chans=1, pretrained=True, num_classes=0)\n",
        "        self.ax_encoder = timm.create_model('convnext_small.fb_in22k_ft_in1k_384', in_chans=1, pretrained=True, num_classes=0)\n",
        "        self.sagt2_flatten = nn.Sequential(nn.AdaptiveAvgPool2d((1,1)),\n",
        "                                    nn.Flatten(1))\n",
        "        self.ax_flatten = nn.Sequential(nn.AdaptiveAvgPool2d((1,1)),\n",
        "                                    nn.Flatten(1))\n",
        "        self.sagt2_num_features = self.sagt2_encoder.num_features\n",
        "        self.ax_num_features = self.ax_encoder.num_features\n",
        "        self.sagt2_head = LSTMMIL(self.sagt2_num_features, 512, 3)\n",
        "        self.ax_head = LSTMMIL(self.ax_num_features, 512, 3)\n",
        "        self.out = nn.Linear(self.sagt2_num_features + self.ax_num_features, 3)\n",
        "        self.aux_out = nn.Linear(self.sagt2_num_features, 3)\n",
        "        #self.dropout = nn.Dropout(0.1)\n",
        "    def forward(self, ax, sagt2, sagt1):\n",
        "        ax_shape = ax.shape\n",
        "        ax = ax.reshape(ax_shape[0]*ax_shape[1]*ax_shape[2], 1, ax_shape[-2], ax_shape[-1])\n",
        "        ax = self.ax_encoder.forward_features(ax)\n",
        "        ax = self.ax_flatten(ax)\n",
        "        ax = ax.reshape(ax_shape[0]*ax_shape[1], ax_shape[2], -1)\n",
        "        ax_weighted_sum, ax_attn = self.ax_head(ax)\n",
        "        ax_attn = ax_attn.reshape(ax_shape[0], ax_shape[1], -1)\n",
        "\n",
        "        sagt2_shape = sagt2.shape\n",
        "        sagt2 = sagt2.reshape(sagt2_shape[0]*sagt2_shape[1]*sagt2_shape[2], 1, sagt2_shape[-2], sagt2_shape[-1])\n",
        "        sagt2 = self.sagt2_encoder.forward_features(sagt2)\n",
        "        sagt2 = self.sagt2_flatten(sagt2)\n",
        "        sagt2 = sagt2.reshape(sagt2_shape[0]*sagt2_shape[1], sagt2_shape[2], -1)\n",
        "        sagt2_weighted_sum, sagt2_attn = self.sagt2_head(sagt2)\n",
        "        sagt2_attn = sagt2_attn.reshape(sagt2_shape[0], sagt2_shape[1], -1)\n",
        "        out = torch.cat([ax_weighted_sum, sagt2_weighted_sum], dim=1)\n",
        "        out = self.out(out)\n",
        "        sagt2_out = self.aux_out(sagt2_weighted_sum)\n",
        "        ax_out = self.aux_out(ax_weighted_sum)\n",
        "        ax_attn = {'L1/L2': ax_attn[:, 0, :], 'L2/L3': ax_attn[:, 1, :], 'L3/L4': ax_attn[:, 2, :], 'L4/L5': ax_attn[:, 3, :], 'L5/S1': ax_attn[:, 4, :]}\n",
        "        sagt2_attn = {'L1/L2': sagt2_attn[:, 0, :], 'L2/L3': sagt2_attn[:, 1, :], 'L3/L4': sagt2_attn[:, 2, :], 'L4/L5': sagt2_attn[:, 3, :], 'L5/S1': sagt2_attn[:, 4, :]}\n",
        "        return out, ax_attn, sagt2_attn, sagt2_out, ax_out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WTZyxTxSw2R"
      },
      "outputs": [],
      "source": [
        "from traitlets.config.loader import ConfigError\n",
        "VAL_SCORE = []\n",
        "\n",
        "class ClassModule(pl.LightningModule):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.condition = config['task']['condition']\n",
        "        if config['task']['condition'] == 'scs':\n",
        "            self.loss_module = SCSNFNSSLoss(is_train=True)\n",
        "            self.val_loss_module = SCSNFNSSLoss(is_train=False)\n",
        "            self.scs_depth_loss_module = SCSDepthDetectLoss()\n",
        "            self.nfn_ss_depth_loss_module = SCSDepthDetectLoss()\n",
        "            self.sagt1_depth_loss_module = SCSDepthDetectLoss()\n",
        "            self.model = SCSMIL()\n",
        "\n",
        "        self.val_step_outputs = []\n",
        "        self.val_step_ax_outputs = []\n",
        "        self.val_step_sagt1_outputs = []\n",
        "        self.val_step_sagt2_outputs = []\n",
        "        self.val_step_labels = []\n",
        "        self.aux_log = {}\n",
        "        #self.ema = ExponentialMovingAverage(self.model.parameters(), decay=0.995)\n",
        "        #self.ema.to(device)\n",
        "\n",
        "        #self.model = torch.optim.swa_utils.AveragedModel(self.model,\n",
        "        #                                                 multi_avg_fn=torch.optim.swa_utils.get_ema_multi_avg_fn(0.999))\n",
        "\n",
        "    def forward(self, batch):\n",
        "        preds = self.model(batch)\n",
        "        return preds\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = AdamW(self.parameters(), **self.config['model'][\"optimizer_params\"])\n",
        "        if self.config['model'][\"scheduler\"][\"name\"] == \"CosineAnnealingLR\":\n",
        "            scheduler = CosineAnnealingLR(\n",
        "                optimizer,\n",
        "                **self.config['model'][\"scheduler\"][\"params\"][\"CosineAnnealingLR\"],\n",
        "            )\n",
        "            lr_scheduler_dict = {\"scheduler\": scheduler, \"interval\": \"step\"}\n",
        "            return {\"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler_dict}\n",
        "        elif self.config['model'][\"scheduler\"][\"name\"] == \"ReduceLROnPlateau\":\n",
        "            scheduler = ReduceLROnPlateau(\n",
        "                optimizer,\n",
        "                **self.config['model'][\"scheduler\"][\"params\"][\"ReduceLROnPlateau\"],\n",
        "            )\n",
        "            lr_scheduler = {\"scheduler\": scheduler, \"monitor\": \"val_loss\"}\n",
        "            return {\"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler}\n",
        "        elif self.config['model']['scheduler']['name'] == 'ChrisLR':\n",
        "            scheduler = ChrisLR(\n",
        "                optimizer,\n",
        "                **self.config['model'][\"scheduler\"][\"params\"][\"ChrisLR\"],\n",
        "            )\n",
        "            lr_scheduler = {\"scheduler\": scheduler, \"monitor\": \"val_loss\"}\n",
        "            return {\"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler}\n",
        "        elif self.config['model']['scheduler']['name'] == 'cosine_with_warmup':\n",
        "            print('cosine with warmup')\n",
        "            print(self.config['model']['scheduler']['params']['cosine_with_warmup'])\n",
        "            scheduler = transformers.get_cosine_schedule_with_warmup(\n",
        "                optimizer,\n",
        "                **self.config['model']['scheduler']['params']['cosine_with_warmup'],\n",
        "            )\n",
        "            lr_scheduler_dict = {\"scheduler\": scheduler, \"interval\": \"step\"}\n",
        "            return {\"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler_dict}\n",
        "        else:\n",
        "            return {\"optimizer\": optimizer}\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        if self.condition == 'scs':\n",
        "            ax, sagt2, sagt1, label, ax_depth, sagt2_depth, sagt1_depth = batch['ax'], batch['sagt2'], batch['sagt1'], batch['label'], batch['ax_depth'], batch['sagt2_depth'], batch['sagt1_depth']\n",
        "            preds, ax_depth_pred, sagt2_depth_pred, sagt2_preds, ax_preds = self.model(ax, sagt2, sagt1)\n",
        "            loss, _, _, _ = self.loss_module(preds, label, ax=ax_preds, sagt2=sagt2_preds)\n",
        "            self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, batch_size=config['train_bs'])\n",
        "            ax_depth_loss = self.nfn_ss_depth_loss_module(ax_depth_pred, ax_depth)\n",
        "            sagt2_depth_loss = self.scs_depth_loss_module(sagt2_depth_pred, sagt2_depth)\n",
        "            self.log('train ax depth loss', ax_depth_loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "            self.log('train sagt2 depth loss', sagt2_depth_loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "            loss = loss + ax_depth_loss*(1/2) + sagt2_depth_loss*(1/2)\n",
        "\n",
        "        for param_group in self.trainer.optimizers[0].param_groups:\n",
        "            lr = param_group[\"lr\"]\n",
        "        self.log(\"lr\", lr, on_step=True, on_epoch=False, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        \"\"\"Add TTA\"\"\"\n",
        "        if self.condition == 'scs':\n",
        "            ax, sagt2, sagt1, label, ax_depth, sagt2_depth, sagt1_depth = batch['ax'], batch['sagt2'], batch['sagt1'], batch['label'], batch['ax_depth'], batch['sagt2_depth'], batch['sagt1_depth']\n",
        "            preds, ax_depth_pred, sagt2_depth_pred, _, _ = self.model(ax=ax, sagt2=sagt2, sagt1=sagt1)\n",
        "            loss, _, _, _ = self.val_loss_module(preds, label)\n",
        "            self.log(\"val_loss_mean\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "            ax_depth_loss = self.nfn_ss_depth_loss_module(ax_depth_pred, ax_depth)\n",
        "            sagt2_depth_loss = self.scs_depth_loss_module(sagt2_depth_pred, sagt2_depth)\n",
        "            self.log('ax depth loss', ax_depth_loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "            self.log('sagt2 depth loss', sagt2_depth_loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "            self.val_step_outputs.append(preds)\n",
        "            self.val_step_labels.append(label)\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "\n",
        "        all_preds = torch.cat(self.val_step_outputs).float()\n",
        "        all_labels = torch.cat(self.val_step_labels)\n",
        "        all_labels = all_labels.to(torch.long)\n",
        "        val_loss, ax, sagt2, sagt1 = self.val_loss_module(all_preds, all_labels)#, ax=all_preds_ax#, sagt1=all_preds_sagt1)\n",
        "        self.log(\"val_loss\", val_loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        print(val_loss)\n",
        "        self.val_step_outputs.clear()\n",
        "        self.val_step_labels.clear()\n",
        "        self.val_step_ax_outputs.clear()\n",
        "        self.val_step_sagt1_outputs.clear()\n",
        "        self.val_step_sagt2_outputs.clear()\n",
        "\n",
        "        #print(self.aux_log['ax_loss'], self.logger.aux_log['sagt1_loss'], self.logger.log_dir['val_loss'])\n",
        "        if self.trainer.global_rank == 0:\n",
        "            print(f\"\\nEpoch: {self.current_epoch}\", flush=True)\n",
        "        return\n",
        "\n",
        "    def optimizer_step(self, *args, **kwargs):\n",
        "        super().optimizer_step(*args, **kwargs)\n",
        "        #self.ema.update()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDmP84kGweLR"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('/content/train.csv')\n",
        "train_dummy = pd.read_csv('/content/train.csv')\n",
        "train_series = pd.read_csv('/content/train_series_descriptions.csv')\n",
        "train_coor = pd.read_csv('/content/expanded_train_label_coordinates.csv')\n",
        "train_coor['y'] = pd.to_numeric(train_coor['y'], errors='coerce')\n",
        "train_coor['x'] = pd.to_numeric(train_coor['x'], errors='coerce')\n",
        "train_coor = train_coor.loc[(~train_coor.x.isna()) & (~train_coor.y.isna())]\n",
        "train_meta = pd.read_parquet('/content/meta.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3c9-MNMNydq2"
      },
      "outputs": [],
      "source": [
        "train_dummy = train_dummy.fillna('Normal/Mild')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPqt8IluwfPF"
      },
      "outputs": [],
      "source": [
        "label = train.columns[1:]\n",
        "kfold = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "for i, (train_idx, valid_idx) in enumerate(kfold.split(train_dummy, train_dummy[label])):\n",
        "    train_dummy.loc[valid_idx, 'fold'] = i\n",
        "train_series = train_series.merge(train_dummy[['study_id', 'fold']], on='study_id')\n",
        "train_coor = train_coor.merge(train_dummy[['study_id', 'fold']], on='study_id')\n",
        "train = train.merge(train_dummy[['study_id', 'fold']], on='study_id')\n",
        "train_meta = train_meta.merge(train_dummy[['study_id', 'fold']], on='study_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujD6iqmdO2Ne"
      },
      "outputs": [],
      "source": [
        "T_MAX = config[\"model\"][\"scheduler\"][\"params\"][\"CosineAnnealingLR\"][\"T_max\"]\n",
        "num_training_steps = config[\"model\"][\"scheduler\"][\"params\"][\"cosine_with_warmup\"][\"num_training_steps\"]\n",
        "num_warmup_steps = config[\"model\"][\"scheduler\"][\"params\"][\"cosine_with_warmup\"][\"num_warmup_steps\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "172207f6137e462099134ca564963a1e",
            "d1883e33264f45de85b93e8c25b5850d",
            "0a8d2bd7bb9647d48eb1b10f0c4ebbf7",
            "9b9e158601a74d38a052cdce1766c818",
            "b21898ad7bf74df5aa659ef2c5b973c1",
            "88ab8ac5203144f8b77cb895560010b7",
            "d69da2e95b21493cb9e4c36584266819",
            "10d807f6722640b39b56275cacc7f51c",
            "2a330956b7704fa69bf27385a1b469be",
            "e253c7e795174f288701219e86cd022e",
            "590ea800626b416ba2f482a0adc0390e",
            "f7e2fd9d45e042a780fb24fc82f28a03",
            "9b095937bdd441969c2f6422bd6a597c",
            "b295cc8852f94f92b68e556dfdda7169",
            "2acabae0b9864d14801203d9283a71c6",
            "a4328299054b4f2dbb246caa12ff52b5",
            "32d542eaebf5401eb377c02273db8d62",
            "a93a710d4c6f4577a6d589703acc93a7",
            "9c03ea40a495434e9755fd9f6b6e81d3",
            "e8257e0a03c241989a0026c3ccd81bb2",
            "ca4d6a04f9e14c2dbc8e8022002ea249",
            "abb04b9dca9348808d5371f1fb555048"
          ]
        },
        "id": "3rCRYqs3TH6I",
        "outputId": "bdff7743-61e8-4526-ed4b-d21cdf16d1fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scs\n",
            "20\n",
            "1578 395\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msyujinko\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>./wandb/run-20241026_113329-9qk37i3a</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/syujinko/rsna_spine_scs_classify/runs/9qk37i3a' target=\"_blank\">convnext-s_lstmmil-fold0</a></strong> to <a href='https://wandb.ai/syujinko/rsna_spine_scs_classify' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/syujinko/rsna_spine_scs_classify' target=\"_blank\">https://wandb.ai/syujinko/rsna_spine_scs_classify</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/syujinko/rsna_spine_scs_classify/runs/9qk37i3a' target=\"_blank\">https://wandb.ai/syujinko/rsna_spine_scs_classify/runs/9qk37i3a</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name                     | Type               | Params | Mode \n",
            "------------------------------------------------------------------------\n",
            "0 | loss_module              | SCSNFNSSLoss       | 0      | train\n",
            "1 | val_loss_module          | SCSNFNSSLoss       | 0      | train\n",
            "2 | scs_depth_loss_module    | SCSDepthDetectLoss | 0      | train\n",
            "3 | nfn_ss_depth_loss_module | SCSDepthDetectLoss | 0      | train\n",
            "4 | sagt1_depth_loss_module  | SCSDepthDetectLoss | 0      | train\n",
            "5 | model                    | SCSMIL             | 113 M  | train\n",
            "------------------------------------------------------------------------\n",
            "113 M     Trainable params\n",
            "0         Non-trainable params\n",
            "113 M     Total params\n",
            "452.374   Total estimated model params size (MB)\n",
            "968       Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cosine with warmup\n",
            "{'num_training_steps': 6312, 'num_warmup_steps': 789, 'num_cycles': 0.5, 'last_epoch': -1}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "172207f6137e462099134ca564963a1e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.0712, device='cuda:0')\n",
            "\n",
            "Epoch: 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f7e2fd9d45e042a780fb24fc82f28a03"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:\n",
            "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'exit' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    573\u001b[0m         )\n\u001b[0;32m--> 574\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1024\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    249\u001b[0m                     \u001b[0;31m# in automatic optimization, there can only be one optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m                     \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautomatic_optimization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\u001b[0m in \u001b[0;36m_optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;31m# model hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         call._call_lightning_module_hook(\n\u001b[0m\u001b[1;32m    269\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[LightningModule]{pl_module.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-3aa439c4d05a>\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;31m#self.ema.update()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/module.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1305\u001b[0m         \"\"\"\n\u001b[0;32m-> 1306\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mstep_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLightningModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/amp.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;31m# note: the scaler will skip the `optimizer.step` if nonfinite gradients are found\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mstep_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainerStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRUNNING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    539\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_SubprocessScriptLauncher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_sigkill_signal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "#######################CLASSIFY#############################\n",
        "print(config['task']['condition'])\n",
        "print(T_MAX)\n",
        "#for i in [5]:\n",
        "for i in [0, 1, 2, 3, 4]:\n",
        "    train_df = train.loc[train.fold != i]\n",
        "    valid_df = train.loc[train.fold == i]\n",
        "    train_df = train_df.drop('fold', axis=1)\n",
        "    valid_df = valid_df.drop('fold', axis=1)\n",
        "    train_series_df = train_series.loc[train_series.fold != i]\n",
        "    valid_series_df = train_series.loc[train_series.fold == i]\n",
        "    train_series_df = train_series_df.drop('fold', axis=1)\n",
        "    valid_series_df = valid_series_df.drop('fold', axis=1)\n",
        "    if config['task']['condition'] != 'nfn':\n",
        "        train_coor_df = train_coor.loc[train_coor.fold != i]\n",
        "        valid_coor_df = train_coor.loc[train_coor.fold == i]\n",
        "        train_coor_df = train_coor_df.drop('fold', axis=1)\n",
        "        valid_coor_df = valid_coor_df.drop('fold', axis=1)\n",
        "    else:\n",
        "        train_coor_df = train_coor.loc[train_coor.fold != i]\n",
        "        valid_coor_df = train_coor.loc[train_coor.fold == i]\n",
        "        #train_coor_df = coor_for_nfn.loc[coor_for_nfn.fold != i]\n",
        "        #valid_coor_df = coor_for_nfn.loc[coor_for_nfn.fold == i]\n",
        "        train_coor_df = train_coor_df.drop('fold', axis=1)\n",
        "        valid_coor_df = valid_coor_df.drop('fold', axis=1)\n",
        "    train_meta_df = train_meta.loc[train_meta.fold != i]\n",
        "    valid_meta_df = train_meta.loc[train_meta.fold == i]\n",
        "    train_meta_df = train_meta_df.drop('fold', axis=1)\n",
        "    valid_meta_df = valid_meta_df.drop('fold', axis=1)\n",
        "\n",
        "    dataset_train = ClassDataset(train_df, train_series_df, train_coor_df, train_meta_df, condition=config['task']['condition'], usage='train')\n",
        "    dataset_validation = ClassDataset(valid_df, valid_series_df, valid_coor_df, valid_meta_df, condition=config['task']['condition'], usage='valid')\n",
        "    #dataset_train = dataset_train[:100]\n",
        "    #dataset_validation = dataset_validation[:100]\n",
        "\n",
        "    data_loader_train = DataLoader(\n",
        "        dataset_train,\n",
        "        batch_size=config[\"train_bs\"],\n",
        "        shuffle=True,\n",
        "        num_workers=4,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "    data_loader_validation = DataLoader(\n",
        "        dataset_validation,\n",
        "        batch_size=config[\"valid_bs\"],\n",
        "        shuffle=False,\n",
        "        num_workers=4,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    print(len(dataset_train), len(dataset_validation))\n",
        "    if config['task']['condition'] == 'scs':\n",
        "        checkpoint_callback = ModelCheckpoint(\n",
        "            save_weights_only=True,\n",
        "            monitor=\"val_loss\",\n",
        "            dirpath=config[\"output_dir\"],\n",
        "            mode='min',\n",
        "            filename=f\"_{config['task']['condition']}_{config['task']['kind']}_5ch_axsagt2-lstm-mil_auxloss_auxdepth_convnext-s-{i}\",\n",
        "            save_top_k=config[\"save_topk\"],\n",
        "            verbose=1,\n",
        "        )\n",
        "\n",
        "    progress_bar_callback = TQDMProgressBar(\n",
        "        refresh_rate=config[\"progress_bar_refresh_rate\"]\n",
        "    )\n",
        "\n",
        "    early_stop_callback = EarlyStopping(**config[\"early_stop\"])\n",
        "    con = config['task']['condition']\n",
        "    kind = config['task']['kind']\n",
        "    wandb_logger = WandbLogger(project=f'rsna_spine_{con}_{kind}', # group runs in \"MNIST\" project\n",
        "                            log_model=False,  # log all new checkpoints during training\n",
        "                            name=f'convnext-s_lstmmil-fold{i}')\n",
        "    trainer = pl.Trainer(\n",
        "        val_check_interval=0.5,\n",
        "        logger=wandb_logger,\n",
        "        callbacks=[checkpoint_callback, early_stop_callback, progress_bar_callback],\n",
        "        **config[\"trainer\"],\n",
        "    )\n",
        "\n",
        "    config[\"model\"][\"scheduler\"][\"params\"][\"CosineAnnealingLR\"][\"T_max\"] = T_MAX*len(data_loader_train)/config[\"trainer\"][\"devices\"]\n",
        "    config[\"model\"][\"scheduler\"][\"params\"][\"cosine_with_warmup\"][\"num_training_steps\"] = int(num_training_steps*len(data_loader_train)/config[\"trainer\"][\"devices\"])\n",
        "    config[\"model\"][\"scheduler\"][\"params\"][\"cosine_with_warmup\"][\"num_warmup_steps\"] = int(num_warmup_steps*len(data_loader_train)/config[\"trainer\"][\"devices\"])\n",
        "    model = ClassModule(config=config)\n",
        "    trainer.fit(model, data_loader_train, data_loader_validation)\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plBVWU1GLjz8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "172207f6137e462099134ca564963a1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d1883e33264f45de85b93e8c25b5850d",
              "IPY_MODEL_0a8d2bd7bb9647d48eb1b10f0c4ebbf7",
              "IPY_MODEL_9b9e158601a74d38a052cdce1766c818"
            ],
            "layout": "IPY_MODEL_b21898ad7bf74df5aa659ef2c5b973c1"
          }
        },
        "d1883e33264f45de85b93e8c25b5850d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88ab8ac5203144f8b77cb895560010b7",
            "placeholder": "​",
            "style": "IPY_MODEL_d69da2e95b21493cb9e4c36584266819",
            "value": "Sanity Checking DataLoader 0: 100%"
          }
        },
        "0a8d2bd7bb9647d48eb1b10f0c4ebbf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10d807f6722640b39b56275cacc7f51c",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a330956b7704fa69bf27385a1b469be",
            "value": 2
          }
        },
        "9b9e158601a74d38a052cdce1766c818": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e253c7e795174f288701219e86cd022e",
            "placeholder": "​",
            "style": "IPY_MODEL_590ea800626b416ba2f482a0adc0390e",
            "value": " 2/2 [00:00&lt;00:00,  2.00it/s]"
          }
        },
        "b21898ad7bf74df5aa659ef2c5b973c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "88ab8ac5203144f8b77cb895560010b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d69da2e95b21493cb9e4c36584266819": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10d807f6722640b39b56275cacc7f51c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a330956b7704fa69bf27385a1b469be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e253c7e795174f288701219e86cd022e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "590ea800626b416ba2f482a0adc0390e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7e2fd9d45e042a780fb24fc82f28a03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b095937bdd441969c2f6422bd6a597c",
              "IPY_MODEL_b295cc8852f94f92b68e556dfdda7169",
              "IPY_MODEL_2acabae0b9864d14801203d9283a71c6"
            ],
            "layout": "IPY_MODEL_a4328299054b4f2dbb246caa12ff52b5"
          }
        },
        "9b095937bdd441969c2f6422bd6a597c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32d542eaebf5401eb377c02273db8d62",
            "placeholder": "​",
            "style": "IPY_MODEL_a93a710d4c6f4577a6d589703acc93a7",
            "value": "Epoch 0:   0%"
          }
        },
        "b295cc8852f94f92b68e556dfdda7169": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c03ea40a495434e9755fd9f6b6e81d3",
            "max": 789,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8257e0a03c241989a0026c3ccd81bb2",
            "value": 0
          }
        },
        "2acabae0b9864d14801203d9283a71c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca4d6a04f9e14c2dbc8e8022002ea249",
            "placeholder": "​",
            "style": "IPY_MODEL_abb04b9dca9348808d5371f1fb555048",
            "value": " 0/789 [00:00&lt;?, ?it/s]"
          }
        },
        "a4328299054b4f2dbb246caa12ff52b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "32d542eaebf5401eb377c02273db8d62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a93a710d4c6f4577a6d589703acc93a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c03ea40a495434e9755fd9f6b6e81d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8257e0a03c241989a0026c3ccd81bb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca4d6a04f9e14c2dbc8e8022002ea249": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abb04b9dca9348808d5371f1fb555048": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}